\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\bibstyle{biblatex}
\bibdata{tesi-blx,llm}
\citation{biblatex-control}
\abx@aux@refcontext{nty/global//global/global/global}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{7}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{8}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Large Language Models (LLMs)}{8}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Neural Networks (NNs)}{8}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural Network, source: \href  {https://www.ibm.com/topics/neural-networks}{IBM}}}{8}{figure.1}\protected@file@percent }
\newlabel{fig:nodeNN}{{1}{8}{Neural Network, source: \href {https://www.ibm.com/topics/neural-networks}{IBM}}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Neural Network node, source: \href  {https://www.briandolhansky.com/blog/artificial-neural-networks-linear-regression-part-1}{Brian Dolhansky blog}}}{9}{figure.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Neural Network labelled training and unlabelled prediction, source: \href  {https://www.briandolhansky.com/blog/artificial-neural-networks-linear-regression-part-1}{Brian Dolhansky blog}}}{10}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}RNNs and LSTMs}{10}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Generative Pre-trained Transformers (GPTs), Tokens and Embeddings}{10}{subsubsection.2.1.3}\protected@file@percent }
\citation{MicrosoftTokens}
\abx@aux@cite{0}{MicrosoftTokens}
\abx@aux@segm{0}{0}{MicrosoftTokens}
\citation{paaß2023foundationmodelsnaturallanguage}
\abx@aux@cite{0}{paaß2023foundationmodelsnaturallanguage}
\abx@aux@segm{0}{0}{paaß2023foundationmodelsnaturallanguage}
\citation{GoogleEmbeddings}
\abx@aux@cite{0}{GoogleEmbeddings}
\abx@aux@segm{0}{0}{GoogleEmbeddings}
\citation{GoogleEmbeddings}
\abx@aux@cite{0}{GoogleEmbeddings}
\abx@aux@segm{0}{0}{GoogleEmbeddings}
\citation{GoogleContextWindow}
\abx@aux@cite{0}{GoogleContextWindow}
\abx@aux@segm{0}{0}{GoogleContextWindow}
\citation{GoogleContextWindow}
\abx@aux@cite{0}{GoogleContextWindow}
\abx@aux@segm{0}{0}{GoogleContextWindow}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example of Word Embedding Table about republican vs democratic speeches, source: \href  {https://www.innerdoc.com/periodic-table-of-nlp-tasks/78-word-embedding-visualization/}{Rob Van Zoest article}}}{12}{figure.4}\protected@file@percent }
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Transformers Architecture}{13}{subsubsection.2.1.4}\protected@file@percent }
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Transformer architecture: the \textbf  {encoder} is the left halve and \textbf  {decoder} the right one, source: \blx@tocontentsinit {0}\cite {vaswani2023attentionneed}}}{14}{figure.5}\protected@file@percent }
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\citation{devlin2019bertpretrainingdeepbidirectional}
\abx@aux@cite{0}{devlin2019bertpretrainingdeepbidirectional}
\abx@aux@segm{0}{0}{devlin2019bertpretrainingdeepbidirectional}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Differences between previously used attention function and multi-head one, source: \blx@tocontentsinit {0}\cite {vaswani2023attentionneed}}}{15}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Sequence-to-Sequence (Seq2Seq)}{15}{subsubsection.2.1.5}\protected@file@percent }
\citation{vaswani2023attentionneed}
\abx@aux@cite{0}{vaswani2023attentionneed}
\abx@aux@segm{0}{0}{vaswani2023attentionneed}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{ReinforcementLearningAnIntroduction}
\abx@aux@cite{0}{ReinforcementLearningAnIntroduction}
\abx@aux@segm{0}{0}{ReinforcementLearningAnIntroduction}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6}Masked Language Modeling (MLM)}{16}{subsubsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7}Causal Language Modeling (CLM)}{16}{subsubsection.2.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8}Reinforce Learning from Human Feedback (RLHF)}{16}{subsubsection.2.1.8}\protected@file@percent }
\citation{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@cite{0}{kaufmann2024surveyreinforcementlearninghuman}
\abx@aux@segm{0}{0}{kaufmann2024surveyreinforcementlearninghuman}
\citation{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\citation{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\citation{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\citation{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\citation{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces "Contrasting the standard RL setting with RLHF in its most common formulation, using a reward model. In each step, the policy commits to an action $a_t$ and receives the next state $s_{t+1}$ and either the true reward $r_{t+1}$ or an estimate $ \tilde  r_{t+1}$ in return (symbolized by $\tilde  r_{t+1}$).\\ In contrast to the standard RL setting, the true reward function is not known in the RLHF setting but instead learned form human feedback. This reward learning process is decoupled from policy learning and can happen fully asynchronously. The dataset consists of a set of queries $q_i$ (e.g., pairs of trajectory fragments) and their labels $l_i$ (e.g., a preference for one of the fragments)"\blx@tocontentsinit {0}\cite {kaufmann2024surveyreinforcementlearninghuman}}}{17}{figure.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}ChatGPT}{17}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Example of mitigation using Adversarial Testing with domain expert, source: \blx@tocontentsinit {0}\cite {openai2024gpt4technicalreport}}}{18}{figure.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gemini}{19}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}gemini-1.5-flash-002}{19}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}gemini-1.5-flash-8b-001}{19}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}gemini-2.0-flash-001}{19}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}gemini-2.0-flash-lite-001}{19}{subsubsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}gemini-2.0-flash-thinking-exp}{19}{subsubsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Gemma}{19}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}gemma3:1b}{19}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}gemma3:4b}{19}{subsubsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Llama}{19}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}llama3.1:8b}{19}{subsubsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}llama3.2:1b}{19}{subsubsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}llama3.2:3b}{19}{subsubsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Artificial General Intelligence (AGI) and AI main goals}{19}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}National Institute of Standard and Technology (NIST) AI risk management framework}{19}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{20}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Analyzed categories}{20}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experimental Design}{20}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}LLMs\_testing Program}{20}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}response\_to\_csv Program}{20}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}LibreOffice Used Macroes}{20}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{21}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{22}{section.5}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{065604F7BFB23A0287FD4C05D761CA0D}
\abx@aux@defaultrefcontext{0}{devlin2019bertpretrainingdeepbidirectional}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{GoogleEmbeddings}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{GoogleContextWindow}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{kaufmann2024surveyreinforcementlearninghuman}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{MicrosoftTokens}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{openai2024gpt4technicalreport}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{paaß2023foundationmodelsnaturallanguage}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{ReinforcementLearningAnIntroduction}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{vaswani2023attentionneed}{nty/global//global/global/global}
\abx@aux@defaultlabelprefix{0}{devlin2019bertpretrainingdeepbidirectional}{}
\abx@aux@defaultlabelprefix{0}{GoogleEmbeddings}{}
\abx@aux@defaultlabelprefix{0}{GoogleContextWindow}{}
\abx@aux@defaultlabelprefix{0}{kaufmann2024surveyreinforcementlearninghuman}{}
\abx@aux@defaultlabelprefix{0}{MicrosoftTokens}{}
\abx@aux@defaultlabelprefix{0}{openai2024gpt4technicalreport}{}
\abx@aux@defaultlabelprefix{0}{paaß2023foundationmodelsnaturallanguage}{}
\abx@aux@defaultlabelprefix{0}{ReinforcementLearningAnIntroduction}{}
\abx@aux@defaultlabelprefix{0}{vaswani2023attentionneed}{}
\gdef \@abspage@last{25}
